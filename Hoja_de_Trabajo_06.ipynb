{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoja de Trabajo 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebastian Solorzano 21826\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manuel Rodas 21509\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análisis de la Escalabilidad del Modelo (Total: 25 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cambie el número de observaciones a 100,000. Explique qué es lo que ocurre en\n",
    "términos de:\n",
    "\n",
    "    1. El tiempo de ejecución para resolver el problemas\n",
    "        - El tiempo de ejecución aumenta considerablemente, ya que al tener más datos, el modelo tiene que hacer más cálculos y por lo tanto, el tiempo de ejecución aumenta.\n",
    "\n",
    "    2. El resultado final vs lo encontrado en clase: es igual, o diferente...¿porqué?\n",
    "        - Si llega a cambiar, ya que al haber mas datos se puede observar un conjunto de datos mas grande y con mas posibilidades por que genera un resultado, mostrando en el modelo 3d una superficie mas compleja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Cambie el número de observaciones a 1,000,000. Explique qué es lo que ocurre\n",
    "en términos de:\n",
    "\n",
    "    1. El tiempo de ejecución para resolver el problemas\n",
    "        - El tiempo de ejecucion actual si fue muy distinto, ya que se tardo mas o menos 12s en poder resolver el problema, el cual es un tiempo considerablemente mayor al anterior.\n",
    "    2. El resultado final vs lo encontrado en clase: es igual, o diferente...¿porqué?\n",
    "        - Es muy diferente, ya que se puede observar una lista mucho mas grande de resultados, puediendo oberservar en la grafica un conjunto de datos mas soliido y con mas posibilidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experimentación con la Tasa de Aprendizaje (Total: 25 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) “Juegue” un poco con el valor de la tasa de aprendizaje, por ejemplo 0.0001,\n",
    "0.001, 0.1, 1. Para cada uno de estos indique:\n",
    "\n",
    "    1. ¿Qué ocurre con el tiempo de ejecución?\n",
    "        - El tiempo de ejecucion varia dependiendo de la tasa de aprendizaje, ya que al tener una tasa de aprendizaje mas alta, el tiempo de ejecucion es menor, ya que el modelo se ajusta mas rapido a los datos, mientras que si es al revez el tiempo es muy probable que sea mayor\n",
    "\n",
    "    2. ¿Qué ocurre con la minimización de la pérdida?\n",
    "        - La minimizacion de la perdida varia dependiendo de la tasa de aprendizaje, ya que si la tasa de aprendizaje es muy alta, la perdida disminuye mas rapido, mientras que si es al revez la perdida disminuye mas lento.\n",
    "\n",
    "    3. ¿Qué ocurre con los pesos y los sesgos?\n",
    "        - Con el valor de 0.02 teniamos pesos y sesgos de [[ 2.00394906] [-2.99542941]] [4.33029287], hora que probamos con 0.0001\n",
    "        [[ 2.00390146][-2.99548765]] [4.34339911] esto nos muestra que los pesos y sesgos varian dependiendo de la tasa de aprendizaje, ya que si la tasa de aprendizaje es muy alta, los pesos y sesgos se ajustan mas rapido, mientras que si es al revez los pesos y sesgos se ajustan mas lento.\n",
    "\n",
    "    4. ¿Qué ocurre con las iteraciones?\n",
    "        - Las iteraciones se vuelven mas rapidas si la tasa de aprendizaje es mas alta, mientras que si es al revez las iteraciones se vuelven mas lentas, esto se debe a como el modelo se ajusta a los datos.\n",
    "\n",
    "    5. ¿El problema queda resuelto o no?\n",
    "        - si queda resuelto en la mayor manera posible\n",
    "\n",
    "    6. ¿Cuál es la apariencia de la última gráfica? ¿Se cumple con la condición de\n",
    "    que sea de 45 grados?\n",
    "\n",
    "        - si se cumple, se puede ver de manera clara que sigue manteniendo una recta en 45 grados, lo cual es lo que se espera de un modelo de regresion lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modificación de la Función de Pérdida (Total: 25 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Cambie la función de pérdida “L2-norm” a la misma pero sin dividir por 2.\n",
    "    1. El tiempo que se tarda el algoritmo en terminar, comparado a lo que vimos en clase\n",
    "        - El tiempo de ejecución no cambio mucho después de modificar la función de pérdida. La división por 2 es computacionalmente barata y no afecta de manera significativa el tiempo total de ejecución\n",
    "        \n",
    "    2. Si la pérdida se minimiza igual que lo que vimos en clase\n",
    "        - La modificación eliminando la división por 2 en la función de pérdida no afecta la forma en que se minimiza la pérdida. Se seguirá ajustando los pesos y sesgos de manera que la pérdida se minimice en cada iteración.\n",
    "\n",
    "    3. Si los pesos y sesgos son parecidos a los vistos en clase\n",
    "        - Después de modificar la función de pérdida, los valores de los pesos y sesgos cambiaron con los obtenidos anteriormente. Esto ocurre debido a que la función de pérdida está relacionada con la actualización de los parámetros del modelo. La diferencia en los valores de los pesos y sesgos no indica que el modelo sea mejor o peor.\n",
    "\n",
    "    4. Si el problema se resuelve como ocurrió en clase\n",
    "        - El problema sigue siendo el mismo después de la modificación de la función de pérdida. El objetivo sigue siendo minimizar la función de pérdida, que representa la discrepancia entre las predicciones del modelo y las metas reales.\n",
    "\n",
    "    5. Si se obtiene un mejor resultado al hacer más iteraciones\n",
    "        -  Obtener una pérdida menor después de más iteraciones no indica un mejor rendimiento del modelo. Una disminución continua de la pérdida en el conjunto de entrenamiento indica que el modelo está aprendiendo más sobre los datos de entrenamiento, pero esto conduce al sobreajuste si el modelo se vuelve demasiado específico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Cambie la función de pérdida de la “L2-norm” a “L1-norm”.\n",
    "    1. El tiempo que se tarda el algoritmo en terminar, comparado a lo que vimos en clase\n",
    "        - El tiempo de ejecución no cambia mucho al cambiar la función de perdida. La diferencia en la función de pérdida no afecta directamente al tiempo de ejecución del algoritmo.\n",
    "\n",
    "    2. Si la pérdida se minimiza igual que lo que vimos en clase\n",
    "        - La pérdida se minimiza de manera diferente con L1-norm en comparación con la L2-norm. Pero en términos de cómo se minimiza la pérdida, ambos métodos siguen el mismo principio de descenso de gradiente, ajustando los parámetros del modelo para reducir la pérdida.\n",
    "\n",
    "    3. Si los pesos y sesgos son parecidos a los vistos en clase\n",
    "        - Con los valores de los pesos y sesgos obtenidos con L2-norm y L1-norm, se puede observar que hay diferencias significativas en los valores obtenidos. Los valores obtenidos con L1-norm son mayores en magnitud y muestran una diferencia más pronunciada entre los pesos y el sesgo en comparación con los valores obtenidos con L2-norm.\n",
    "\n",
    "    4. Si el problema se resuelve como ocurrió en clase\n",
    "        - Sí, el problema se resuelve utilizando el mismo enfoque de optimización. Sin embargo, debido a que se ha cambiado la función de pérdida L1-norm tiende a producir soluciones más dispersas, lo que puede afectar la convergencia del algoritmo y la naturaleza de los valores finales de los parámetros del modelo.\n",
    "\n",
    "    5. Si se obtiene un mejor resultado al hacer más iteraciones\n",
    "        - L1-norm puede ser más lenta en converger que L2-norm. Sin embargo, hacer más iteraciones puede permitir que el algoritmo converja a una solución más óptima en términos de la función de pérdida L1-norm.\n",
    "\n",
    "    6. ¿Tendrá una de estas más limitaciones que la otra?\n",
    "        - L2-norm es más sensible a los errores grandes y puede ser más propensa al sobreajuste si hay valores atípicos en los datos, pero es más fácil de optimizar matemáticamente. Por otro lado, L1-norm es más robusta a los valores atípicos y tiende a producir soluciones más dispersas y más esparsas, pero puede ser más difícil de optimizar y puede converger más lentamente en algunos casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación y Evaluación de una Nueva Función (Total: 25 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Cree una función f(x1, x2) = 13 * x1 + 7 * x2 - 12\n",
    "    1. ¿Funciona el algoritmo de la misma forma?\n",
    "        - Comparando los resultados con la nueva función, se puede observar que el algoritmo ha ajustado los pesos y sesgos para minimizar la función de pérdida de manera efectiva. Sin embargo, los resultados obtenidos son diferentes de los obtenidos anteriormente, lo que indica que el algoritmo ha convergido a una solución diferente. Esto era de esperar, dado que la nueva función de generación de metas es diferente de la función anterior. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
